## Software Testing: Perspectives


- Hi, now we're going to describe a few testing perspectives, including a few that you may have already heard of in a bit more detail. 

- Probably the most well-known distinction in testing is between black-box and white-box testing. You've likely heard the term black-box before. 

- It's synonymous with airplanes. The black-box of the navigation in an airplane that records what happens in a crash. What we mean in this context, is the idea that when you peer into the black-box, you see nothing. 

- What this means is, in testing, is that you aren't allowed to look at the code. In fact you should know nothing about the code when determining how you will test the system to ensure it's working properly. 

- These are all behavioral approaches. If I do this, will it do this the way that I expect?

- Here's how quick to respond or how resilient the system is. Those kinds of things. The mirror to that is white-box testing. Testing which is primarily based on the program structure, the code itself. 

- These techniques are primarily about making sure that you test all the lines of code and attack fragile or error prone elements that had been used in building the program. 

- And when I say error prone, I don't mean that they're bad things to use. Arrays are very fundamental to how programs work. But working near the ends of the array, both the beginning and end bounds, that tends to be a prime location to make mistakes. It's something we call an off by one error. 

- Just by the nature of how arrays work, those mistakes can happen. It's not that arrays are bad, they're in fact very commonplace. It's just that we must take care in how we work with them. 

- And therefore they're prime locations for us to test to make sure that we've done that properly. V & V is a whole life cycle process. When we talk about validation and verification, we should be doing that at every step. 

- Making sure that what we built is what we set out to build and making sure that it's going to meet the user's needs. This is more obviously true in agile teams. With a user representative commonly a key component of your team, they, the user, can and should and need to provide validation of work after the developer has potentially verified that they have done what they set out to do at every step of the project.

- Of course, finding and ultimately fixing defects or bugs is important. We want to provide quality in our product, but it's not only about find and fix for behavior. It's also about measuring or evaluating the system in other vectors of quality. 

- Yes, it works, but how well does it work when the CPU is at 90% load? If there are a lot of users all on the system at the same time, does the database connection usage reach its limit? What happens if a server shuts down unexpectedly? And how easy is it to hack into the system and corrupt data? These are things that aren't necessarily behavioral of does the system do this, but it's still very important to how the system works.

- Now we can talk about stages of testing. When we talk about unit testing, we're talking about testing of individual components. This usually means an individual method or potentially one class within the solution.

- Then module testing is a set of units that come together as a collection or dependent components. This is the first form of integration testing. How we test when things come together. because it's one thing to test them isolation, it's another when for example, you have two drawers and you can't open them because the drawer will run into the handle of the other one. That's a form of integration testing that we have to do.

- Then once we have modules set up, we can do subsystem and even component testing. Testing collections of modules integrated into subsystems. 

- This testing is primarily concerned with ensuring that the interfaces between the subsystems and components, between the module's components often divided between developing teams, meet the specifications they were given. 

- Because an individual developing team can build their module, or even their component and it looks like it works. But then when you put the components or modules together, they don't quite work the way they thought they would work together. Testing of this kind includes that integration of components. Making sure that components work together as intended.

- Going up again, we move from subsystem to full system testing. Testing the complete system prior to delivery. There's a lot that goes into the developing team, making sure that the whole system is working and it gets back to some things we talked about before with security, performance, usability, that kind of thing. And lastly, and I don't have an animation for this, but the acceptance testing, testing by users. 

- This is sometimes called alpha testing, beta testing and in fact, it is true that in deployment, once it's actually delivered to users, even though we don't call it an alpha or beta, when the users use it, find bugs and report them back to us somehow, that's still a form of testing. 

- It's probably the worst form of testing because you don't want those things to get to real users. But it's still a form of testing, a form of finding defects. 

- Black-box and white-box, verification and validation, or V and V as it's sometimes called. Unit, module, component, system, acceptance testing, they're all just different ways of considering your testing as a whole, broken down into categories. 

- But none of these are mutually exclusive, you should be well-versed in all of the perspective techniques and employ each of them. Sometimes in isolation, for example, black-box versus white-box should be separated, but still, you use them together to get the best chance of successful overall testing.